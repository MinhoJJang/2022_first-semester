메모리는 엄밀히 말하면 모든 형태의 전자 스토리지이지만, 가장 많이 사용되는 것은 빠르고 일시적인 스토리지 형태입니다. 컴퓨터의 CPU가 필요한 모든 데이터를 가져오기 위해 하드 드라이브에 계속 액세스해야 하는 경우, 하드 드라이브는 매우 느리게 작동합니다. 정보를 메모리에 보관하면 CPU는 훨씬 더 빠르게 액세스할 수 있습니다. 대부분의 메모리 형식은 데이터를 일시적으로 저장하는 것을 목적으로 합니다.

CPU는 다른 계층에 따라 메모리에 액세스합니다. 영구 스토리지(하드 드라이브)나 입력(키보드)에 의한 것이라도, 대부분의 데이터는 우선 랜덤 액세스 메모리(RAM)에 저장됩니다. 그런 다음 CPU는 액세스에 필요한 데이터 조각을 종종 캐시에 저장하고 레지스터에 특정 특수 명령을 유지합니다. 캐시와 레지스터에 대해서는 나중에 이야기하겠습니다.

CPU, 하드 드라이브, 운영 체제 등 컴퓨터 내의 모든 컴포넌트는 한 팀이 되어 동작합니다.메모리는 이 팀에서 가장 중요한 부품 중 하나입니다. 컴퓨터를 켜는 순간부터 컴퓨터를 종료할 때까지 CPU는 지속적으로 메모리를 사용합니다. 일반적인 시나리오를 살펴보겠습니다.

컴퓨터를 켭니다. 컴퓨터는 읽기 전용 메모리(ROM)로부터 데이터를 로드해, 전원 투입시의 셀프 테스트(POST)를 실행해, 모든 주요 컴포넌트가 정상적으로 기능하고 있는 것을 확인합니다. 이 테스트의 일환으로 메모리 컨트롤러는 빠른 읽기/쓰기 조작으로 모든 메모리 주소를 체크하여 메모리 칩에 오류가 없는지 확인합니다. 읽기/쓰기란 데이터를 비트에 쓴 다음 해당 비트에서 읽는 것을 의미합니다. 컴퓨터가 ROM에서 기본 입출력 시스템(BIOS)을 로드합니다. BIOS는 스토리지 디바이스, 부트 시퀀스, 보안, 플러그 앤 플레이(자동 디바이스 인식) 기능 및 기타 몇 가지 항목에 대한 가장 기본적인 정보를 제공합니다. 컴퓨터는 OS를 하드 디스크(HDD)에서 시스템의 RAM으로 로드합니다. 통상, operating system의 중요한 부품은, 컴퓨터의 전원이 들어가 있는 한, RAM 에 보관 유지됩니다. 이것에 의해, CPU는 operating system에 곧바로 액세스 할 수 있게 되어, 시스템 전체의 퍼포먼스와 기능이 향상됩니다. 애플리케이션을 열면 RAM에 로드됩니다. RAM 사용량을 절약하기 위해 많은 응용 프로그램이 처음에는 프로그램의 필수 부분만 로드한 다음 필요에 따라 다른 부분을 로드합니다. 응용 프로그램이 로드되면 해당 응용 프로그램에서 사용하기 위해 열려 있는 모든 파일이 RAM에 로드됩니다. 파일을 저장하고 응용 프로그램을 닫으면 해당 파일이 지정된 스토리지 디바이스에 기록되고 해당 파일과 응용 프로그램이 RAM에서 삭제됩니다.위의 목록에서는 무언가를 로드하거나 열 때마다 RAM에 저장됩니다. 이는 단순히 CPU가 그 정보에 더 쉽게 접근할 수 있도록 컴퓨터의 임시 저장 영역에 저장되었음을 의미합니다. CPU는 RAM에 필요한 데이터를 요청하여 처리한 후 새로운 데이터를 RAM에 연속적으로 씁니다. 대부분의 컴퓨터에서는 CPU와 RAM 간의 데이터 교환이 초당 수백만 번 발생합니다. 응용 프로그램이 닫히면 응용 프로그램과 그에 부수되는 모든 파일이 새 데이터를 저장할 공간을 확보하기 위해 RAM에서 삭제(삭제)됩니다. 변경된 파일이 삭제되기 전에 영구 저장 장치에 저장되지 않으면 파일이 손실됩니다.

데스크톱 컴퓨터에 대해 자주 묻는 질문 중 하나는 "컴퓨터는 왜 이렇게 많은 메모리 시스템을 필요로 하는가?"입니다.

컴퓨터 메모리의 종류입니다.
일반 시스템에는 다음이 있습니다.

수준 1 및 수준 2 캐시입니다.
일반 시스템 RAM입니다.
가상 메모리입니다.
하드 디스크요

왜 이렇게 많내구요? 이 질문에 대한 답은 메모리에 대해 많은 것을 가르쳐 줄 수 있어요!

빠르고 강력한 CPU는 성능을 극대화하기 위해 대량의 데이터에 빠르고 쉽게 액세스해야 합니다. CPU가 필요한 데이터를 가져올 수 없는 경우, CPU는 말 그대로 데이터를 중지하고 기다립니다. 약 1기가헤르츠의 속도로 실행되는 최신 CPU는 초당 수십억 바이트의 엄청난 양의 데이터를 소비할 수 있습니다. 컴퓨터 디자이너들이 직면하는 문제는 1기가헤르츠 CPU를 따라잡을 수 있는 메모리가 엄청나게 비싸다는 것입니다. 즉, 대량으로 살 수 있는 것보다 훨씬 더 비쌉니다.

컴퓨터 설계자들은 값비싼 메모리를 소량으로 사용한 다음 더 저렴한 대용량의 메모리로 백업함으로써 비용 문제를 해결했습니다.

오늘날 널리 사용되는 가장 저렴한 형태의 읽기/쓰기 메모리는 하드 디스크입니다. 하드 디스크는 많은 양의 저렴한 영구 스토리지를 제공합니다. 하드 디스크 공간을 메가바이트당 페니에 구입할 수 있지만 하드 디스크에서 1메가바이트를 읽는 데는 상당한 시간(초당 약 1초)이 걸릴 수 있습니다. 하드 디스크의 스토리지 공간은 매우 저렴하고 풍부하기 때문에 가상 메모리라고 하는 CPU 메모리 계층의 마지막 단계를 구성합니다.

계층의 다음 수준은 RAM입니다. RAM 작동 방식에서 RAM에 대해 자세히 설명하지만 여기서는 RAM에 대한 몇 가지 요점이 중요합니다.

CPU의 비트 크기는 RAM에서 동시에 액세스할 수 있는 정보의 바이트 수를 나타냅니다. 예를 들어, 16비트 CPU는 한 번에 2바이트(1바이트 = 8비트, 따라서 16비트 = 2바이트)를 처리하고, 64비트 CPU는 한 번에 8바이트를 처리할 수 있습니다.

메가헤르츠(MHz)는 CPU의 처리 속도 또는 클럭 사이클을 초당 수백만 단위로 측정한 것입니다. 따라서 32비트 800MHz Pentium III는 잠재적으로 초당 8억 번 4바이트를 동시에 처리할 수 있습니다(파이프라이닝에 기반할 수 있음). 메모리 시스템의 목표는 이러한 요구 사항을 충족하는 것입니다.

컴퓨터의 시스템 RAM만으로는 CPU의 속도를 따라잡을 수 없을 만큼 빠르지 않습니다. 따라서 캐시가 필요합니다(나중에 설명). 그러나 RAM이 빠를수록 좋습니다. 오늘날 대부분의 칩은 50~70나노초의 주기 속도로 작동합니다. 읽기/쓰기 속도는 일반적으로 DRAM, SDRAM, RAMBUS와 같이 사용되는 RAM 유형의 함수입니다. 우리는 이러한 다양한 종류의 기억력에 대해 나중에 이야기 할 것입니다.

먼저 시스템 RAM에 대해 살펴보겠습니다.

시스템 RAM 속도는 버스 폭 및 버스 속도에 의해 제어됩니다. 버스 폭은 CPU로 동시에 전송할 수 있는 비트 수를 의미하며, 버스 속도는 초당 비트 그룹을 전송할 수 있는 횟수를 의미합니다. 데이터가 메모리에서 CPU로 이동할 때마다 버스 주기가 발생합니다. 예를 들어, 100MHz 32비트 버스는 이론적으로 4바이트(32비트 나누기 8=4바이트)의 데이터를 초당 1억 번 CPU로 전송할 수 있는 반면, 66MHz 16비트 버스는 초당 6600만 번 2바이트의 데이터를 전송할 수 있습니다. 계산을 해보면 버스 폭을 16비트에서 32비트로, 이 예에서는 66MHz에서 100MHz로 변경하기만 하면 초당 3배(4억 바이트 대 1억3천200만 바이트)의 데이터가 CPU로 전달됩니다.

실제로 RAM은 일반적으로 최적의 속도로 작동하지 않습니다. 대기 시간은 방정식을 근본적으로 바꿉니다. 지연 시간은 정보를 읽는 데 필요한 클럭 주기 수를 나타냅니다. 예를 들어, 100MHz 정격의 RAM은 0.00000001초 내에 비트를 전송할 수 있지만 첫 번째 비트에 대한 읽기 프로세스를 시작하는 데 0.00000005초가 걸릴 수 있습니다. 지연 시간을 보정하기 위해 CPU는 버스트 모드라는 특수 기술을 사용합니다.

버스트 모드는 CPU가 요청한 데이터가 순차적 메모리 셀에 저장될 것이라는 예상에 따라 달라집니다. 메모리 컨트롤러는 CPU가 작동 중인 모든 것이 동일한 일련의 메모리 주소에서 계속 전송되므로 여러 비트의 데이터를 함께 읽을 수 있습니다. 즉, 첫 번째 비트만 지연 시간의 영향을 완전히 받으며 연속 비트를 읽는 데 걸리는 시간이 현저히 줄어듭니다. 메모리의 정격 버스트 모드는 일반적으로 대시로 구분된 네 개의 숫자로 표시됩니다. 첫 번째 숫자는 읽기 작업을 시작하는 데 필요한 클럭 사이클 수를 나타내고, 두 번째, 세 번째 및 네 번째 숫자는 워드라인이라고도 하는 행의 각 연속 비트를 읽는 데 필요한 사이클 수를 나타냅니다. 예를 들어: 5-1-1은 첫 번째 비트를 읽는 데 5주기가 걸리고 그 후 각 비트에 대해 1주기가 걸린다는 것을 알려줍니다. 이 수치가 낮을수록 메모리의 성능이 향상됩니다.

버스트 모드는 지연 시간의 영향을 최소화하는 또 다른 수단인 파이프라인과 함께 자주 사용됩니다. 파이프라인은 데이터 검색을 일종의 조립 라인 프로세스로 구성합니다. 메모리 컨트롤러는 메모리에서 하나 이상의 단어를 동시에 읽고, 현재 단어를 CPU로 보내고, 하나 이상의 단어를 메모리 셀에 씁니다. 버스트 모드와 파이프라이닝을 함께 사용하면 지연 시간으로 인한 지연을 크게 줄일 수 있습니다.

그렇다면 가장 빠르고 넓은 메모리를 구입하지 않으시겠습니까? 메모리 버스의 속도와 폭은 시스템의 버스와 일치해야 합니다. 66-MHz 시스템에서는 100MHz에서 작동하도록 설계된 메모리를 사용할 수 있지만 버스의 66MHz 속도로 실행되므로 이점이 없으며 32비트 메모리는 16비트 버스에 맞지 않습니다.

와이드하고 빠른 버스를 사용하더라도 데이터가 메모리 카드에서 CPU로 전송되는 데 CPU가 실제로 데이터를 처리하는 데 걸리는 시간보다 더 오래 걸립니다. 캐시가 필요한 부분입니다.

캐시는 CPU에서 가장 자주 사용하는 데이터를 즉시 사용할 수 있도록 하여 이러한 병목 현상을 완화하도록 설계되었습니다. 기본 또는 수준 1 캐시라고 하는 소량의 메모리를 CPU에 직접 구축하면 됩니다. 수준 1 캐시는 매우 작으며 일반적으로 2KB(KB)에서 64KB 사이는 매우 작습니다.

보조 또는 수준 2 캐시는 일반적으로 CPU 근처에 있는 메모리 카드에 있습니다. 수준 2 캐시는 CPU에 직접 연결됩니다. 마더보드의 전용 집적 회로인 L2 컨트롤러는 CPU의 수준 2 캐시 사용을 규제합니다. 수준 2 캐시의 크기는 CPU에 따라 256KB에서 2MB까지입니다. 대부분의 시스템에서는 CPU에 필요한 데이터가 캐쉬에서 약 95% 정도 액세스되므로 CPU가 기본 메모리에서 데이터를 기다려야 할 때 필요한 오버헤드가 크게 줄어듭니다.

일부 저렴한 시스템에서는 레벨 2 캐시가 모두 필요하지 않습니다. 현재 많은 고성능 CPU에는 실제로 CPU 칩 자체에 레벨 2 캐시가 내장되어 있습니다. 따라서 레벨 2 캐시의 크기와 캐시가 온보드(CPU)에 있는지 여부가 CPU 성능의 주요 결정 요소입니다. 캐시에 대한 자세한 내용은 캐싱 작동 방식을 참조하십시오.

특정 유형의 RAM인 정적 임의 액세스 메모리(SRAM)는 주로 캐시에 사용됩니다. SRAM은 각 메모리 셀에 대해 일반적으로 4-6개의 다중 트랜지스터를 사용합니다. 이 시스템에는 두 상태 사이를 전환하거나 플립 플랍하는 쌍안정 멀티바이버레이터로 알려진 외부 게이트 어레이가 있습니다. 즉, DRAM처럼 지속적으로 업데이트하지 않아도 됩니다. 각 셀은 전원이 공급되는 한 데이터를 유지합니다. SRAM은 지속적인 업데이트 없이 매우 빠르게 작동할 수 있습니다. 그러나 각 셀의 복잡성으로 인해 표준 RAM으로 사용하기에는 엄청나게 많은 비용이 듭니다.

캐시의 SRAM은 비동기 또는 동기일 수 있습니다. 동기식 SRAM은 CPU의 속도와 정확히 일치하도록 설계되었지만 비동기식은 그렇지 않습니다. 그 작은 타이밍이 성능의 차이를 만듭니다. CPU의 클럭 속도를 맞추는 것이 좋으므로 항상 동기화된 SRAM을 찾습니다(다양한 유형의 RAM에 대한 자세한 내용은 RAM 작동 방식 참조).

메모리의 마지막 단계는 레지스터입니다. CPU에 직접 내장된 메모리 셀로 CPU에 필요한 특정 데이터, 특히 ALU(산술 및 논리 유닛)가 포함되어 있습니다. CPU 자체의 필수 요소인 이러한 구성 요소는 CPU가 처리할 정보를 전송하는 컴파일러에 의해 직접 제어됩니다. 레지스터에 대한 자세한 내용은 마이크로프로세서의 작동 방식을 참조하십시오.

시스템 메모리에 대한 간편한 인쇄 가이드를 위해 HowStuffWorks 컴퓨터 메모리 용어 목록을 인쇄할 수 있습니다.

컴퓨터 메모리와 관련 항목에 대한 자세한 내용은 아래 링크를 참조하십시오.
